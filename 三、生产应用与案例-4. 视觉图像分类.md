# [C# TensorFlow 2 入门教程](<https://github.com/SciSharp/TensorFlow.NET-Tutorials>)

# 三、生产应用与案例

## 4. 视觉图像分类

除了特定的读码和测量外，机器视觉检测领域的三大主要任务为图像分类、目标检测和图像分割。自从深度学习方法引入到机器视觉行业，经过这些年的飞速发展，从早期的图像分类一直到后来的目标检测和图像分割，深度学习逐渐在机器视觉领域占据绝对的主导地位。我们可以通过下图来快速了解区分“图像分类、目标检测和图像分割”这3种不同的视觉检测任务：

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210214001821495.png" alt="image-20210214001821495" style="zoom:80%;" />

本章节我们主要讲解深度学习在视觉领域的最基础应用-图像分类，简单地说，图像分类就是要回答上图左1的这张图片是一只猫的问题。

对于人类来说，这是一个非常自然而然的事情，我们每天都在做大量的图像分类任务，从早晨起床识别衣服进行穿衣，识别各种早餐和餐具进行就餐，识别马路上的车辆、交通标识和行人，到达工作场所后识别各种文件和物体……我们几乎没有意识到自己每天都在完成大量的图像分类任务。

这个看似非常简单的事情，对于计算机视觉来说，却并没有这么容易。因为对于计算机而言，它们是无法像人一样看到整张图片并进行直观理解的，计算机看到的只是一个3维矩阵，包含“长×宽×通道数”个像素点，每个像素点的灰度值在0（纯黑）~255（纯白）之间，计算机需要根据这么多的像素点灰度的值进行逻辑运算，最后判定给出图像的分类标签。下图描述了计算机看到的图片：

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210214010255264.png" alt="image-20210214010255264" style="zoom:80%;" />

计算机在实际识别的过程中，会遇到很多复杂的情况和困难，比如：物体旋转或尺寸缩放、图像变形或拍摄视角影响、光影变换、复杂背景干扰等等，很多情况下，传统机器视觉的CV算法已经无法根据预设规则进行分类筛选。在这种传统机器视觉的瓶颈领域，正好是深度学习大展拳脚的时候，我们可以通过深度学习的图像分类算法模型，“喂”给模型大量的带已分类标签的图像，模型自己去总结和学习图像的特征，最终通过多轮训练得到一个指定任务的分类器，这个分类器可以准确地对未知的相同任务的图像进行分类。这就是深度学习的大致流程，而深度学习视觉图像分类领域，最流行也最基础的就是卷积神经网络（CNN）。

说到卷积神经网络（Convolutional Neural Network, CNN），我们肯定要知道卷积神经网络之父-Yann LeCun。在神经网络和深度学习领域，Yann LeCun 可以说是元老级人物。通过利用局部相关性和权值共享的思想，Yann Lecun 在1986年提出了卷积神经网络，并于1998年在 IEEE 上发表了一篇42页的长文，文中首次提出卷积-池化-全连接的神经网络结构，由 LeCun 提出的七层网络命名为 LeNet5。该网络模型的简略结构是“输入-卷积-池化-卷积-池化-卷积（全连接）-全连接-全连接（输出）”，如下图所示：

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210214012114638.png" alt="image-20210214012114638" style="zoom:67%;" />

卷积神经网络的模型结构和前面章节讲述的全连接网络类似，只是新加入了一些卷积层和池化层。全连接层在处理高维度的图片、视频数据时往往出现网络参数量巨大，训练非常困难的问题，而卷积神经网络的局部感受野和权值共享的特性可以很好地解决训练问题，随着深度学习的兴盛，卷积神经网络在机器视觉领域的表现大大超越了其它算法模型，呈现统治视觉领域之势。

通过增加、删除或者调整组合 CNN 网络的结构，我们可以得到很多的图像分类模型，其中比较流行的有 AlexNet、VGG、GoogLeNet、ResNet、DenseNet 等。同时很多常用的目标检测模型，例如 RCNN、Fast RCNN、Faster RCNN 等，也是基于 CNN 扩展而来，可以说，CNN 网络是深度学习视觉领域最重要的基石。





### 4.1 卷积神经网络（CNN）实现图像分类

**图像分类任务描述：**

我们通过手写字符集 MNIST 的图像分类识别，来演示一个简单的7层卷积神经网络。



**数据集简述：**

数据集是最为经典的 MNIST 手写字符集，在前文已经详细介绍该数据集的出处，此处不再赘述。

我们可以通过下述方法载入 MNIST 数据集，并查看该数据集的形状，其中变量 x_train，y_train，x_test，y_test 的类型为 NDArray ：

```c#
NDArray x_test, y_test, x_train, y_train;
((x_train, y_train), (x_test, y_test)) = keras.datasets.mnist.load_data();
```

你可以在VS里面设置断点查看变量的内容，我们看到训练集的大小是 60000 张图片和标签，测试集的大小是 10000 张图片和标签，每张图片的尺寸是 28 pixel × 28 pixel ：

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210217211134982.png" alt="image-20210217211134982" style="zoom:50%;" />

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210217211203178.png" alt="image-20210217211203178" style="zoom:50%;" />

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210217211045036.png" alt="image-20210217211045036" style="zoom:50%;" />

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210217211230449.png" alt="image-20210217211230449" style="zoom:50%;" />

你也可以通过 SharpCV 的 cv2.imshow() 方法显示图片进行查看，我们看到 0~9 这 10 个不同的手写字符，大致如下图所示：

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210217213807048.png" alt="image-20210217213807048" style="zoom:67%;" />



**网络模型搭建：**

我们通过使用 Keras 中的函数式 Functional 方式搭建一个简单的7层卷积神经网络。并使用 Keras 中内置的 model.compile() 进行模型编译，使用 model.fit() 进行模型训练，最后使用 model.evaluate() 进行模型评估。



**完整解决方案的代码实操：**

**① 创建解决方案**

创建新项目。

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210217215353989.png" alt="image-20210217215353989" style="zoom:67%;" />

选择 .NET Core 。

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210217215423134.png" alt="image-20210217215423134" style="zoom:67%;" />

输入项目名和项目路径，并点击创建项目。

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210217215634704.png" alt="image-20210217215634704" style="zoom:67%;" />

配置项目属性的 .NET 5.0 版本 和 编译器版本 x64 位。

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210217235904092.png" alt="image-20210217235904092" style="zoom:67%;" />

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210217215954572.png" alt="image-20210217215954572" style="zoom: 63%;" />



**② 添加类库引用和命名空间**

通过 NuGet 安装最新版本的 TensorFlow.NET、SciSharp.TensorFlow.Redist（ GPU 版本对应的为SciSharp.TensorFlow.Redist-Windows-GPU ） 和 TensorFlow.Keras，安装完如下图所示：

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210217234946232.png" alt="image-20210217234946232" style="zoom:67%;" />

添加命名空间。

```c#
using NumSharp;
using Tensorflow.Keras.Engine;
using Tensorflow.Keras.Layers;
using static Tensorflow.KerasApi;
```



**③ 主程序代码**

准备工作：声明变量，“网络模型”、“网络层”和“数据集”。

```c#
Model model;
LayersApi layers = new LayersApi();
NDArray x_train, y_train, x_test, y_test;
```

第一步：载入 MNIST 数据集并归一化处理。

```c#
// Step-1. Prepare Data
(x_train, y_train, x_test, y_test) = keras.datasets.mnist.load_data();
x_train = x_train.reshape(60000, 28, 28, 1) / 255f;
x_test = x_test.reshape(10000, 28, 28, 1) / 255f;
```

第二步：使用 Keras 的函数式 (Functional方式) 搭建7层的卷积神经网络模型并编译模型。

```c#
// Step-2. Build CNN Model with Keras Functional
// input layer
var inputs = keras.Input(shape: (28, 28, 1));
// 1st convolution layer
var outputs = layers.Conv2D(32, kernel_size: 5, activation: keras.activations.Relu).Apply(inputs);
// 2nd maxpooling layer
outputs = layers.MaxPooling2D(2, strides: 2).Apply(outputs);
// 3nd convolution layer
outputs = layers.Conv2D(64, kernel_size: 3, activation: keras.activations.Relu).Apply(outputs);
// 4nd maxpooling layer
outputs = layers.MaxPooling2D(2, strides: 2).Apply(outputs);
// 5nd flatten layer
outputs = layers.Flatten().Apply(outputs);
// 6nd dense layer
outputs = layers.Dense(1024).Apply(outputs);
// 7nd dropout layer
outputs = layers.Dropout(rate: 0.5f).Apply(outputs);
// output layer
outputs = layers.Dense(10).Apply(outputs);
// build keras model
model = keras.Model(inputs, outputs, name: "mnist_model");
// show model summary
model.summary();
// compile keras model into tensorflow's static graph
model.compile(loss: keras.losses.SparseCategoricalCrossentropy(from_logits: true),
              optimizer: keras.optimizers.Adam(learning_rate: 0.001f),
              metrics: new[] { "accuracy" });
```

第三步：训练模型和评估模型。

```c#
// Step-3. Train Model
// train model by feeding data and labels.
model.fit(x_train, y_train, batch_size: 64, epochs: 2, validation_split: 0.2f);
// evluate the model
model.evaluate(x_test, y_test, verbose: 2);
```



完整的控制台运行代码如下：

```c#
using NumSharp;
using Tensorflow.Keras.Engine;
using Tensorflow.Keras.Layers;
using static Tensorflow.KerasApi;

namespace MnistCNNKerasFunctional
{
    class Program
    {
        static void Main(string[] args)
        {
            MnistCNN cnn = new MnistCNN();
            cnn.Main();
        }

        class MnistCNN
        {
            Model model;
            LayersApi layers = new LayersApi();
            NDArray x_train, y_train, x_test, y_test;
            public void Main()
            {
                // Step-1. Prepare Data
                (x_train, y_train, x_test, y_test) = keras.datasets.mnist.load_data();
                x_train = x_train.reshape(60000, 28, 28, 1) / 255f;
                x_test = x_test.reshape(10000, 28, 28, 1) / 255f;

                // Step-2. Build CNN Model with Keras Functional
                // input layer
                var inputs = keras.Input(shape: (28, 28, 1));
                // 1st convolution layer
                var outputs = layers.Conv2D(32, kernel_size: 5, activation: keras.activations.Relu).Apply(inputs);
                // 2nd maxpooling layer
                outputs = layers.MaxPooling2D(2, strides: 2).Apply(outputs);
                // 3nd convolution layer
                outputs = layers.Conv2D(64, kernel_size: 3, activation: keras.activations.Relu).Apply(outputs);
                // 4nd maxpooling layer
                outputs = layers.MaxPooling2D(2, strides: 2).Apply(outputs);
                // 5nd flatten layer
                outputs = layers.Flatten().Apply(outputs);
                // 6nd dense layer
                outputs = layers.Dense(1024).Apply(outputs);
                // 7nd dropout layer
                outputs = layers.Dropout(rate: 0.5f).Apply(outputs);
                // output layer
                outputs = layers.Dense(10).Apply(outputs);
                // build keras model
                model = keras.Model(inputs, outputs, name: "mnist_model");
                // show model summary
                model.summary();
                // compile keras model into tensorflow's static graph
                model.compile(loss: keras.losses.SparseCategoricalCrossentropy(from_logits: true),
                    optimizer: keras.optimizers.Adam(learning_rate: 0.001f),
                    metrics: new[] { "accuracy" });

                // Step-3. Train Model
                // train model by feeding data and labels.
                model.fit(x_train, y_train, batch_size: 64, epochs: 2, validation_split: 0.2f);
                // evluate the model
                model.evaluate(x_test, y_test, verbose: 2);

            }
        }
    }
}
```



**④ 程序运行**

运行程序，我们看到终端正常输出了网络模型的结果和参数列表，同时训练过程中随着轮次的迭代，验证集准确度不断提升，最终在测试集上的准确度大约达到了 97%。通过这个训练结果，我们可以看到，卷积神经网络模型（CNN）相比较前文的全连接神经网络（DNN）的大约 93% 的准确率，性能上有了一定的提升。

```c#
Model: mnist_model
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 28, 28, 1)         0
_________________________________________________________________
conv2d (Conv2D)              (None, 24, 24, 32)        832
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 10, 10, 64)        18496
_________________________________________________________________
max_pooling2d_1 (MaxPooling2D) (None, 5, 5, 64)        0
_________________________________________________________________
flatten (Flatten)            (None, 1600)              0
_________________________________________________________________
dense (Dense)                (None, 1024)              1639424
_________________________________________________________________
dropout (Dropout)            (None, 1024)              0
_________________________________________________________________
dense_1 (Dense)              (None, 10)                10250
=================================================================
Total params: 1669002
Trainable params: 1669002
Non-trainable params: 0
_________________________________________________________________
Epoch: 001/002, Step: 0001/0750, loss: 2.342649, accuracy: 0.015625
Epoch: 001/002, Step: 0002/0750, loss: 2.312991, accuracy: 0.062500
Epoch: 001/002, Step: 0003/0750, loss: 2.293373, accuracy: 0.088542
Epoch: 001/002, Step: 0004/0750, loss: 2.261313, accuracy: 0.125000
Epoch: 001/002, Step: 0005/0750, loss: 2.203913, accuracy: 0.190625
Epoch: 001/002, Step: 0006/0750, loss: 2.151764, accuracy: 0.244792
Epoch: 001/002, Step: 0007/0750, loss: 2.118946, accuracy: 0.272321
Epoch: 001/002, Step: 0008/0750, loss: 2.064438, accuracy: 0.314453
Epoch: 001/002, Step: 0009/0750, loss: 1.996795, accuracy: 0.357639
Epoch: 001/002, Step: 0010/0750, loss: 1.932693, accuracy: 0.392188
Epoch: 001/002, Step: 0011/0750, loss: 1.857887, accuracy: 0.426136
Epoch: 001/002, Step: 0012/0750, loss: 1.784158, accuracy: 0.453125
Epoch: 001/002, Step: 0013/0750, loss: 1.710757, accuracy: 0.481971
Epoch: 001/002, Step: 0014/0750, loss: 1.643326, accuracy: 0.506696
Epoch: 001/002, Step: 0015/0750, loss: 1.582916, accuracy: 0.525000
Epoch: 001/002, Step: 0016/0750, loss: 1.534452, accuracy: 0.537109
Epoch: 001/002, Step: 0017/0750, loss: 1.480093, accuracy: 0.553309
Epoch: 001/002, Step: 0018/0750, loss: 1.421180, accuracy: 0.571181
Epoch: 001/002, Step: 0019/0750, loss: 1.380466, accuracy: 0.584704
……(中间轮次的输出省略显示)
Epoch: 002/002, Step: 0745/0750, loss: 0.094977, accuracy: 0.970987
Epoch: 002/002, Step: 0746/0750, loss: 0.095171, accuracy: 0.970954
Epoch: 002/002, Step: 0747/0750, loss: 0.095221, accuracy: 0.970942
Epoch: 002/002, Step: 0748/0750, loss: 0.095166, accuracy: 0.970961
Epoch: 002/002, Step: 0749/0750, loss: 0.095111, accuracy: 0.970981
Epoch: 002/002, Step: 0750/0750, loss: 0.095067, accuracy: 0.970990
Testing...
iterator: 1, loss: 0.09048357, accuracy: 0.97236377
```



### 4.2 卷积神经网络详解

通过 Keras 的 model.summary() 方法可以输出网络的结构和参数信息，我们再来详细解析下这个7层的卷积神经网络。

model.summary() 的输出如下：

```c#
Model: mnist_model
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 28, 28, 1)         0
_________________________________________________________________
conv2d (Conv2D)              (None, 24, 24, 32)        832
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 10, 10, 64)        18496
_________________________________________________________________
max_pooling2d_1 (MaxPooling2D) (None, 5, 5, 64)        0
_________________________________________________________________
flatten (Flatten)            (None, 1600)              0
_________________________________________________________________
dense (Dense)                (None, 1024)              1639424
_________________________________________________________________
dropout (Dropout)            (None, 1024)              0
_________________________________________________________________
dense_1 (Dense)              (None, 10)                10250
=================================================================
Total params: 1669002
Trainable params: 1669002
Non-trainable params: 0
_________________________________________________________________
```

总体来说，这个网络的堆叠结构为：① 输入层（InputLayer，28\*28）→② 卷积层（Conv2D，参数量832）→③ 池化层（MaxPooling2D，2\*2）→④ 卷积层（Conv2D，参数量18496）→⑤ 池化层（MaxPooling2D，2\*2）→⑥ 展平层（Flatten） →⑦ 全连接层（Dense，参数量1639424）→⑧ 随机丢弃层（Dropout，50%概率）→⑨ 输出层（Dense，全连接层，参数量10250）。通过参数量我们可以直观地看到，卷积层的参数量是要远远小于全连接层的，这也是卷积层的特点之一。

接下来，我们通过 “功能原理和运行方式” 这2个方面来详细说说什么是 卷积层、池化层、展平层和随机丢弃层。



#### 4.2.1 卷积层详解

刚才我们提到了卷积的一个主要特性，是解决传统全连接神经网络的参数量巨大、随着输入数据尺寸增大会出现计算量爆炸的问题（例如本文中的卷积神经网络示例代码中，仅1个全连接层 dense 的参数量 1639424 ，就占整个网络总参数量 1669002 的  92% 比例，全连接层的参数量占比十分惊人）。接下来我们会通过尽量通俗易懂的方式来学习卷积层，公式推导方面会略微减少一些，感兴趣的读者可以查阅专业的资料来深入学习。



**① 功能原理**

我们先从数学上看卷积的最初的定义。卷积这个名词的数学含义是指一种和“加减乘除”一样的运算，其运算的主要操作是将两个函数的其中一个先翻转平移，然后再与另一个函数相乘后的累加和。

对于定义在连续域的函数，卷积定义为：

 <img src="三、生产应用与案例-4. 视觉图像分类.assets/9693e23c88d7c92b4e023bf15ba2c6b2.png" alt="(f * g )(t) = \int f(\tau) g(t - \tau)\, d\tau" style="zoom:67%;" />

对于定义在离散域的函数，卷积定义为：

<img src="三、生产应用与案例-4. 视觉图像分类.assets/87d76adca3c545f6832302da3f434c38.png" alt="(f * g)[m] = \sum_n {f[n] g[m - n]}" style="zoom:67%;" />

简单地理解上面2个公式，就是先将一个 g 函数翻转，然后和 f 进行滑动叠加。在连续情况下，叠加指的是对两个函数的乘积求积分，在离散情况下就是加权求和，为简单起见就统一称为叠加。

因为卷积运算涉及到了积分和级数的操作，理解起来可能不是特别直观。不过没有关系，接下来我们要讲的是机器视觉领域的“二维卷积Conv-2D”，这个“二维卷积”操作是机器视觉中最常见的图像预处理方式，也是深度学习中的“卷积”操作，这个“卷积”并非刚才的数学中的卷积（只是采用同一个名称），严格意义上来说，是衍生自数学中的 cross-correlation 的一种操作。这里，我们撇开图像中二维卷积的公式，直接举例进行说明。

和数学中的卷积原理有些类似，机器视觉和深度学习中对图像的卷积操作，其过程也是 **“二维卷积核逐个滑过原始图像的每块像素区域，加权求和后生成新的图像”**，我们来由简至深地通过一组图片观察这个有趣的过程。

**单通道灰度图的卷积示意：**

首先，我们有一个 7×7 的原始图像（0 和 1 简单示意灰度值）和一个 3×3 的卷积核。

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210223200817282.png" alt="image-20210223200817282" style="zoom:67%;" />

然后，我们把原始图像的第一块 3×3 的区域和卷积对应地进行**“点乘”**而后求和，作为新图像的第1颗像素。

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210223200954377.png" alt="image-20210223200954377" style="zoom: 50%;" />

我们沿着图像像素从左往右，从上往下，逐行地重复这个**“点乘求和”**的过程，最终得到卷积后的输出图像。

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210223201839482.png" alt="image-20210223201839482" style="zoom: 50%;" />

这样就完成了一幅灰度图像的二维卷积操作，细心的读者可能发现了，卷积后的输出图像的尺寸比原图像在宽和高2个方向上都减少了2个像素，原因很简单，就是 3×3 的卷积核的中心无法遍历到图像的像素边缘导致。解决这个问题的方法叫做 Padding，就是在原始图像四周手动填充一圈像素，例如填充灰度“0”，然后对填充后的图像进行卷积处理，这样输出的图像就和原始图像尺寸保持一致了。如下图所示：

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210224204100452.png" alt="image-20210224204100452" style="zoom: 50%;" />

那么，在机器视觉领域，对图像做卷积会有什么作用呢？我们来通过几个经典的图像卷积核的例子来说明卷积在图像处理方面的意义。

**原始图像：**

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210224213015888.png" alt="image-20210224213015888" style="zoom:67%;" />

**图像模糊（左边是卷积核，右边是卷积后的图像）：**

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210224213126402.png" alt="image-20210224213126402" style="zoom:67%;" />

**图像锐化：**

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210224213221396.png" alt="image-20210224213221396" style="zoom:67%;" />

**轮廓提取：**

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210224213809680.png" alt="image-20210224213809680" style="zoom:67%;" />

**浮雕效果：**

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210224213519065.png" alt="image-20210224213519065" style="zoom:67%;" />

**顶部索贝尔（也有底部、左侧和右侧，求差的方向不同，效果也不同）：**

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210224213705696.png" alt="image-20210224213705696" style="zoom:67%;" />

还有很多很多自定义的卷积核，可以呈现很多有趣的图像处理。细心的读者可能会发现，卷积核的制作有个共同点，就是9个格子中所有权重相加的和始终为1（也可以不为1，并非强制限制条件），这是为了防止加权求和后的灰度出现上溢或者下溢的情况，也是减少图像灰度信息的损失。卷积核还有一个特质，就是大部分卷积核的尺寸都为奇数，这是因为卷积运算最终的结果是赋值给中心点像素的，如果尺寸为偶数的话，就无法有效定义中心点像素。

了解了图像中的卷积，我们来看下深度学习中的卷积运算。深度学习中的卷积运算和图像中的卷积运算原理完全一致，只不过输出的不一定是图像，一般只是特征信息。我们来逐步观察深度学习中的卷积操作。

上面我们已经了解的是灰度图像的卷积和边缘填充（Padding）操作，下一步我们先来看深度学习中彩色图像的卷积和填充（Padding）操作。

深度学习中的彩色图像的卷积操作，主要方式是将彩色图像分离为R（红色 Red）、G（绿色 Green）、B（蓝色 Blue）三个通道的灰度图像，然后采用3个独立的卷积核进行卷积运算，卷积运算后的3个像素结果值求和，最后加上偏置项Bias，输出作为输出图像的第1颗左上角像素的值。不断迭代上述过程，从左往右，从上往下，滑动卷积核重复加权求和，最终输出了单通道的二维特征矩阵。多通道单卷积核（每个通道对应1个卷积核）输出值的计算过程如下图所示：

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210227001500045.png" alt="image-20210227001500045" style="zoom:67%;" />

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210227001536289.png" alt="image-20210227001536289" style="zoom:67%;" />

（……中间部分动画省略）

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210227001713881.png" alt="image-20210227001713881" style="zoom:67%;" />

上述过程仅演示卷积的正向运算，暂时不涉及梯度下降和反向传播。

刚才演示的是多通道（三通道彩色图）单卷积核的情况，输出为单个二维特征矩阵，但实际在深度学习中，一般来说，一层卷积层会采用多个卷积核，即多通道多卷积核运算。该运算可理解拆分为多个单卷积核的独立运算（上述过程）后独立产生输出，最终输出多个二维特征矩阵，每个卷积核都对应输出一个二维特征矩阵。运算过程如下图所示：

**卷积核1#：**

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210227004029419.png" alt="image-20210227004029419" style="zoom:67%;" />

（……中间部分动画省略）

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210227004110591.png" alt="image-20210227004110591" style="zoom:67%;" />

**卷积核2#：**

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210227004154254.png" alt="image-20210227004154254" style="zoom:67%;" />

（……中间部分动画省略）

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210227004229757.png" alt="image-20210227004229757" style="zoom:67%;" />

上面演示的是2个卷积核的例子，实际卷积层的卷积核数量可以通过修改卷积层方法的参数1 filters 的 Int 值进行设置。例如，`conv1 = layers.Conv2D(32, kernel_size: 5, activation: keras.activations.Relu);` ，Conv2D 方法中的参数1的值 32 即代表该卷积层有32个卷积核。summary 输出显示的卷积层 conv1 的参数量仅为 832，计算方式为 (5 × 5 × 1 + 1) × 32 = 832，即 32 个 5 乘 5 的卷积核 再乘输入通道数 1 加上偏置值bias 。同样的，第2层卷积层 conv2d_1 的参数量为 18496，计算方式为 (3 × 3 ×32 + 1) × 64 = 18496 ，即 64 个 3 乘 3 的卷积核 再乘输入通道数 32 加上偏置值bias 。

如果想要更深入理解卷积层，我们可以将其类比为大脑的视觉皮层。我们前文介绍的全连接神经网络可以类比我们人的神经细胞模型，每个神经元都与上一层的所有神经元相连。不过视觉皮层的神经元的工作原理大不相同，这里要提一个“感受野（Receptive Field）“的概念，即视觉皮层中的神经元并非与前一层的所有神经元相连，而只是感受一片区域内的视觉信号，并只对局部区域的视觉刺激进行反应。CNN 中的卷积层正体现了这一特性。

稠密的全连接层具有参数冗余、计算代价高等问题点，无法高效提取图像的特征。而显示生活中的真实图像，一般都具有局部相关性，即某个局部区域内部的关联较大，空间分布距离越远，图像数据关联性越少。卷积层正是利用了图像的这一特征，通过有效提取图像的局部特征，运用卷积核的权值共享的方式，实现降低网络参数量、提升计算性能的特点。在卷积神经网络实践的过程中，我们也发现，各个卷积层确实提取到了很多“有用的特征”和“类似人脑的视觉学习方式”，例如浅层卷积层大多提取图像整体的灰度分布、轮廓信息和各个局部关联特性，深层卷积层则从图像整体宏观角度，看到了图像整体的共有特性和“可描述的显著特性”，这也促进了深度学习的可解释性的研究。



**② 运行方式**

了解了卷积层的运行原理，我们再来整体直观地看下卷积神经网络的流程。下述是一个包含4个卷积层的网络模型：

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210301204612720.png" alt="image-20210301204612720" style="zoom:67%;" />

第1个卷积层 conv_1_1，输入为“杯子”的RGB 3个通道的图像，卷积核数量为10组（每组都包含3个独立的卷积核对应3个通道），输出为10个卷积后的特征矩阵。第1组卷积核的运算如下图所示：

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210301205416901.png" alt="image-20210301205416901" style="zoom:67%;" />

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210301205603938.png" alt="image-20210301205603938" style="zoom:67%;" />

第2层 conv_1_2 、第3层 conv_2_1 和第4层 conv_2_2 卷积层，输入均为前一层的10个输出特征矩阵（来自激活函数 relu 或者 max_pool 网络层），卷积核数量为10组（每组都包含10个独立的卷积核对应10个输入），输出为10个卷积后的特征矩阵。我们举例看下第2层 conv_1_2 的第1组卷积核的运算，如下图所示：

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210301210146362.png" alt="image-20210301210146362" style="zoom:67%;" />

<img src="三、生产应用与案例-4. 视觉图像分类.assets/image-20210301210254505.png" alt="image-20210301210254505" style="zoom:67%;" />

从图中我们也可以直观地看到，不同的卷积层会提取出“杯子”的不同特征，有些卷积层会提取出杯子的“圆形杯口”轮廓，有些卷积层则会提取出杯子内“茶水”的灰度分布。总结卷积层的运行方式，就是通过大量不同的卷积核，提取出图像大量的“局部”特征，参与神经网络的训练，最后不同特征通过权重组合判定图像的类别。特别是对于计算机视觉的分类问题，卷积网络具有很好的泛化能力。



#### 4.2.2 池化层、展平层和随机丢弃层详解

































#### 4.2.3 一些经典的卷积神经网络模型简述





原理、功能、运算效果、参数量说明



### 4.3 深入了解卷积神经网络





